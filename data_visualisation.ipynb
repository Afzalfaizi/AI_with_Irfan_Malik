{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGDV6Jr7evninGbQnP1Kev",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Afzalfaizi/AI_with_Irfan_Malik/blob/main/data_visualisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGkC6tWpi48k"
      },
      "outputs": [],
      "source": [
        "This note book cover the following concepts\n",
        "\n",
        "1. Pandas\n",
        "2. Data Exploration\n",
        "3. IQR\n",
        "4. Correlation\n",
        "5. Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.0. Importing the installed Libraries**"
      ],
      "metadata": {
        "id": "U_PrjZZ8jH9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns                       #visualisation\n",
        "import matplotlib.pyplot as plt             #visualisation\n",
        "%matplotlib inline\n",
        "sns.set(color_codes=True)"
      ],
      "metadata": {
        "id": "tUIv31UEjKXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.2. Loading the dataset**\n"
      ],
      "metadata": {
        "id": "LoEo5iwxjN_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the data into the pandas data frame is certainly one of the most important steps in EDA, as we can see that the value from the data set is comma-separated. So all we have to do is to just read the CSV into a data frame and pandas data frame does the job for us."
      ],
      "metadata": {
        "id": "HsNKvMv4jPof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get or load the dataset into the notebook, all I did was one trivial step. In Google Colab at the left-hand side of the notebook, you will find a > (greater than symbol). When you click that you will find a tab with three options, you just have to select Files. Then you can easily upload your file with the help of the Upload option. No need to mount to the google drive or use any specific libraries just upload the data set and your job is done. One thing to remember in this step is that uploaded files will get deleted when this runtime is recycled. This is how I got the data set into the notebook."
      ],
      "metadata": {
        "id": "XPLkbRugjSb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"data.csv\")\n",
        "# To display the top 5 rows\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "71Vw6ntljVZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(5)                        # To display the botton 5 rows"
      ],
      "metadata": {
        "id": "ITcpEpkgjaR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.3. Checking the types of data**"
      ],
      "metadata": {
        "id": "QEo4WKYKjeXk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we check for the datatypes because sometimes the MSRP or the price of the car would be stored as a string, if in that case, we have to convert that string to the integer data only then we can plot the data via a graph. Here, in this case, the data is already in integer format so nothing to worry."
      ],
      "metadata": {
        "id": "w8lDv2v1jfTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "id": "_AXOjcq4jiTk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.4. Dropping irrelevant columns**"
      ],
      "metadata": {
        "id": "651bKY6Kjm7l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step is certainly needed in every EDA because sometimes there would be many columns that we never use in such cases dropping is the only solution. In this case, the columns such as Engine Fuel Type, Market Category, Vehicle style, Popularity, Number of doors, Vehicle Size doesn't make any sense to me so I just dropped for this instance."
      ],
      "metadata": {
        "id": "6ikrMN4djn9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop([ 'Vehicle Size'], axis=1)\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "QkT9K6YejqD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.5. Renaming the columns**"
      ],
      "metadata": {
        "id": "Obuv8hocjvwp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this instance, most of the column names are very confusing to read, so I just tweaked their column names. This is a good approach it improves the readability of the data set."
      ],
      "metadata": {
        "id": "yZxcaaWGjyFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={\"Engine HP\": \"HP\", \"Engine Cylinders\": \"Cylinders\", \"Transmission Type\": \"Transmission\", \"Driven_Wheels\": \"Drive Mode\",\"highway MPG\": \"MPG-H\", \"city mpg\": \"MPG-C\", \"MSRP\": \"Price\" })\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "5-aoPv9Rj00s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.6. Dropping the duplicate rows**"
      ],
      "metadata": {
        "id": "lO6o73g4j565"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is often a handy thing to do because a huge data set as in this case contains more than 10, 000 rows often have some duplicate data which might be disturbing, so here I remove all the duplicate value from the data-set. For example prior to removing I had 11914 rows of data but after removing the duplicates 10925 data meaning that I had 989 of duplicate data."
      ],
      "metadata": {
        "id": "9w4wRQPlj7yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "EDM_KWdvj-nE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "duplicate_rows_df = df[df.duplicated()]\n",
        "print(\"number of duplicate rows: \", duplicate_rows_df.shape)"
      ],
      "metadata": {
        "id": "508O-zsHkC2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let us remove the duplicate data because it's ok to remove them."
      ],
      "metadata": {
        "id": "0qEbyEXokGNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.7. Counting the number of Rows**"
      ],
      "metadata": {
        "id": "tG0xfqLwkInI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()      # Used to count the number of rows"
      ],
      "metadata": {
        "id": "S6PXdB8rkKl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So seen above there are 11914 rows and we are removing 989 rows of duplicate data."
      ],
      "metadata": {
        "id": "JreWQbP1kOGq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1.8. Dropping the Duplicate Values**"
      ],
      "metadata": {
        "id": "DuksPEiYkPt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop_duplicates()\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "BkvZXbLtkR-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.count()"
      ],
      "metadata": {
        "id": "QTiZFU77kX2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **2.0. Dropping the missing or null values.**"
      ],
      "metadata": {
        "id": "jHXahqcxkbxe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is mostly similar to the previous step but in here all the missing values are detected and are dropped later. Now, this is not a good approach to do so, because many people just replace the missing values with the mean or the average of that column, but in this case, I just dropped that missing values. This is because there is nearly 100 missing value compared to 10, 000 values this is a small number and this is negligible so I just dropped those values."
      ],
      "metadata": {
        "id": "5T8wPcpPkdG_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "Nr64L3mAkf3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the reason in the above step while counting both Cylinders and Horsepower (HP) had 10856 and 10895 over 10925 rows."
      ],
      "metadata": {
        "id": "CWOchwDNkmBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna()    # Dropping the missing values.\n",
        "df.count()"
      ],
      "metadata": {
        "id": "-_505Ue7kpkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have removed all the rows which contain the Null or N/A values (Cylinders and Horsepower (HP)).\n"
      ],
      "metadata": {
        "id": "zHFAbo36ksry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())   # After dropping the values"
      ],
      "metadata": {
        "id": "17dE5rkpktu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.0. Detecting Outliers**"
      ],
      "metadata": {
        "id": "AlWPGv9vkzew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An outlier is a point or set of points that are different from other points. Sometimes they can be very high or very low. It's often a good idea to detect and remove the outliers. Because outliers are one of the primary reasons for resulting in a less accurate model. Hence it's a good idea to remove them. The outlier detection and removing that I am going to perform is called IQR score technique. Often outliers can be seen with visualizations using a box plot. Shown below are the box plot of MSRP, Cylinders, Horsepower and EngineSize. Herein all the plots, you can find some points are outside the box they are none other than outliers. The technique of finding and removing outlier that I am performing in this assignment is taken help of a tutorial from[ towards data science](https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba)."
      ],
      "metadata": {
        "id": "NZlUuZotk2tx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=df['Price'])"
      ],
      "metadata": {
        "id": "mW2ZCx2wk564"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=df['HP'])"
      ],
      "metadata": {
        "id": "pCkpw4Fbk9Mn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=df['Cylinders'])"
      ],
      "metadata": {
        "id": "eEdOi519lAAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Q1 = df.quantile(0.25)\n",
        "Q3 = df.quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "print(IQR)"
      ],
      "metadata": {
        "id": "CIjTXhcwlAwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **4.0. Correlation of different features**"
      ],
      "metadata": {
        "id": "Kdzrs_JylGBY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.corr()"
      ],
      "metadata": {
        "id": "FjLRss-ElH7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9. Plot different features against one another (scatter), against frequency (histogram)"
      ],
      "metadata": {
        "id": "ex7MZ-NBlRFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "cspJATY9lQz_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Histogram\n",
        "\n",
        "Histogram refers to the frequency of occurrence of variables in an interval. In this case, there are mainly 10 different types of car manufacturing companies, but it is often important to know who has the most number of cars. To do this histogram is one of the trivial solutions which lets us know the total number of car manufactured by a different company."
      ],
      "metadata": {
        "id": "0i3sX75-lTzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Price vs Make**"
      ],
      "metadata": {
        "id": "apvJYAcclWeO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.Make.value_counts().nlargest(15).plot(kind='bar', figsize=(10,5))\n",
        "plt.title(\"Price of cars by make\")\n",
        "plt.ylabel('price of cars')\n",
        "plt.xlabel('Make');"
      ],
      "metadata": {
        "id": "RvCGgYjElbWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Number of Cars vs Make**"
      ],
      "metadata": {
        "id": "fNnMPW6slgnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.Make.value_counts().nlargest(40).plot(kind='bar', figsize=(10,5))\n",
        "plt.title(\"Number of cars by make\")\n",
        "plt.ylabel('Number of cars')\n",
        "plt.xlabel('Make');"
      ],
      "metadata": {
        "id": "exp4vB0QljPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data vs the Year**"
      ],
      "metadata": {
        "id": "hiP4_wB7lmT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.Year.value_counts().plot(kind='pie')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "M7g11spaloJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "4Zx6sGKslsW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.Make.value_counts().nlargest(20).plot(kind='bar', figsize=(15, 10)) # figsize=(15, 10)\n",
        "plt.title(\"Number of HP by car\")\n",
        "plt.ylabel('Number of HP')\n",
        "plt.xlabel('Make');"
      ],
      "metadata": {
        "id": "SGk_Jonklu5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5.0. Heat Maps**"
      ],
      "metadata": {
        "id": "5t89elJ-lyH6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjusting the Size of Figure\n",
        "plt.figure(figsize=(10,5))\n",
        "# calculating the Correlation\n",
        "correlation = df.corr()\n",
        "# Displaying the correlation using the Heap Map\n",
        "sns.heatmap(correlation,cmap=\"BrBG\",annot=True) # Br: Brown. B: Blue, G: Green\n",
        "\n",
        "#correlation"
      ],
      "metadata": {
        "id": "Sjo7O24Fl6cC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
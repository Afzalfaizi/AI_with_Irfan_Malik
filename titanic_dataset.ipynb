{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiid7+zfgE5mJ2gQ37fVjM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Afzalfaizi/AI_with_Irfan_Malik/blob/main/titanic_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcCYwBJHlqC7"
      },
      "outputs": [],
      "source": [
        "This note book cover the following concepts\n",
        "\n",
        "1. Visualization\n",
        "2. Sea born"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import sklearn\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.rcParams[\"figure.figsize\"] = [10,5]"
      ],
      "metadata": {
        "id": "dcCDHteymCDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ignore warnings\n",
        "\n",
        "import warnings\n",
        "# Set the warning filter to ignore FutureWarning\n",
        "warnings.simplefilter(action = \"ignore\", category = FutureWarning)"
      ],
      "metadata": {
        "id": "8Z2a5huZmFg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "jTn-b795mJOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "https://seaborn.pydata.org/tutorial.html"
      ],
      "metadata": {
        "id": "uJHWpk6umPN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Seaborn functionality**\n",
        "\n",
        "Seaborn offers lot of functionality which makes it effective for many data visualization tasks. These functionalities are listed below:-\n",
        "\n",
        "•\tSeaborn provides a dataset-oriented API to examine relationships between variables.\n",
        "\n",
        "•\tIt provides functions to fit and visualize linear regression models for different types of independent and dependent variables.\n",
        "\n",
        "•\tSeaborn provide functions for visualizing univariate and bivariate distributions and for comparing them between subsets of data.\n",
        "\n",
        "•\tIt provides plotting functions for using categorical variables to show observations or aggregate statistics.\n",
        "\n",
        "•\tIt helps us to visualize matrices of data and use clustering algorithms to discover structure in those matrices.\n",
        "\n",
        "•\tSeaborn provides a plotting function to plot statistical time series data. The function provides flexible estimation and representation of uncertainty around the estimate.\n",
        "\n",
        "•\tIt provide tools for choosing styles, colour palettes, palette widgets and utility functions. These tools help us to make beautiful plots that reveal patterns in the data.\n",
        "\n",
        "•\tIt provides several built-in themes for producing stylish looking Matplotlib graphics.\n"
      ],
      "metadata": {
        "id": "uJFz3ZkumTky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Seaborn colour palette**\n",
        "\n",
        "\n",
        "Colour plays very important role in data visualization. Colour adds various dimensions to a plot when used effectively.\n",
        "A palette means a flat surface on which a painter mixes paints.\n",
        "\n",
        "\n",
        "Seaborn provides a function called **color_palette()**. It can be used to give colours to plots and adding aesthetic value to it. It return a list of colors defining a color palette.\n",
        "\n",
        "\n",
        "There are several readily available Seaborn palettes. These are:-\n",
        "\n",
        "•\tDeep\n",
        "\n",
        "•\tMuted\n",
        "\n",
        "•\tBright\n",
        "\n",
        "•\tPastel\n",
        "\n",
        "•\tDark\n",
        "\n",
        "•\tColorblind\n",
        "\n",
        "Besides these we can also create new palettes.\n",
        "\n",
        "There is another function **seaborn.palplot()** which deals with color palettes. This function plots the color palette as a horizontal array.\n"
      ],
      "metadata": {
        "id": "p7u5meTCmYDJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Categorical Color Palettes**\n",
        "\n",
        "Qualitative or categorical palettes are best suitable to plot the categorical data as follows:-\n"
      ],
      "metadata": {
        "id": "-0Plo-bmmbuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "current_palette1 = sns.color_palette()\n",
        "\n",
        "sns.palplot(current_palette1)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "jNL0N2IamcjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Continous Color Palettes**\n",
        "\n",
        "Sequential plots are suitable to express the distribution of data ranging from relative lower values to higher values within a range. Appending an additional character \"s\" to the color passed to the color parameter will plot the Sequential plot.\n",
        "\n",
        "We need to append 's' to the parameter like 'Greens' as follows:-\n"
      ],
      "metadata": {
        "id": "LD5vGpoQmh1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "current_palette2 = sns.color_palette()\n",
        "\n",
        "sns.palplot( sns.color_palette(\"Reds\"))\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3jmTC_HFmisc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Diverging Color Palette**\n",
        "\n",
        "Diverging palettes use two different colors. Each color represents variation in the value ranging from a common point in either direction.\n",
        "\n",
        "We assume plotting the data ranging from -1 to 1. The values from -1 to 0 takes one color and 0 to +1 takes another color.\n",
        "\n",
        "By default, the values are centered from zero. We can control it with parameter center by passing a value as follows:-\n"
      ],
      "metadata": {
        "id": "v4t2zpOPmn2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "current_palette3 = sns.color_palette()\n",
        "\n",
        "sns.palplot(sns.color_palette(\"BrBG\", 20))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VMfDqGsBmpUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Seaborn on Titanic dataset**\n",
        "\n",
        "In this tutorial, we will learn to use different Searbon plot functions to get insight from data. We will use Titanic dataset to experiment these searbon kind of plot.\n",
        "\n",
        "### Prerequisites\n",
        "You should have a basic understanding of ***computer programming terminologies***. A basic understanding of ***Python*** and any of the programming languages is a plus. Seaborn library is built on top of Matplotlib. Having basic idea of ***Matplotlib*** will help you understand this tutorial in a better way.\n"
      ],
      "metadata": {
        "id": "e5ZkapzMmuJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sequential Color Palettes**"
      ],
      "metadata": {
        "id": "secKZcQdmxXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "current_palette2 = sns.color_palette()\n",
        "\n",
        "sns.palplot( sns.color_palette(\"colorblind\"))\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4vz6tE2Amx9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import the Data\n",
        "Let's extract the our **Titanic data** from the .csv file, create a  pandas DataFrame and look at the available indicators:\n",
        "\n",
        "- ***Survived***: Outcome of survival (0 = No; 1 = Yes)\n",
        "- ***Pclass***: Socio-economic class (1 = Upper class; 2 = Middle class; 3 = Lower class)\n",
        "- ***Name***: Name of passenger\n",
        "- ***Sex***: Sex of the passenger\n",
        "- ***Age***: Age of the passenger (Some entries contain NaN)\n",
        "- ***SibSp***: Number of siblings and spouses of the passenger aboard\n",
        "- ***Parch***: Number of parents and children of the passenger aboard\n",
        "- ***Ticket***: Ticket number of the passenger\n",
        "- ***Fare***: Fare paid by the passenger\n",
        "- ***Cabin***: Cabin number of the passenger (Some entries contain NaN)\n",
        "- ***Embarked***: Port of embarkation of the passenger (C = Cherbourg; Q = Queenstown; S = Southampton)"
      ],
      "metadata": {
        "id": "e4ihfpLxm7Ty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_data = pd.read_csv('/content/titanic_dataset.csv')"
      ],
      "metadata": {
        "id": "a24AmSPtm_e7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_data.shape"
      ],
      "metadata": {
        "id": "alWaIszsnCrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_data.head()"
      ],
      "metadata": {
        "id": "YeGURhUXnEkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Go back to the Table of Contents](#table_of_contents)\n",
        "** **\n",
        "<a id = \"Distribution\"></a>\n",
        "## 2. Distribution plots\n",
        "Distribution of data is the foremost thing that we need to understand while analysing the data. Here, we will see how seaborn helps us in understanding the distribution of our data.\n",
        "\n",
        "<a id = \"distplot\"></a>\n",
        "### 2.1. distplot\n",
        "The `distplot()` function provides the most convenient way to take a quick look at univariate distribution. This function will plot a `histogram` that fits the **kernel density estimation(KDE)** of the data.\n",
        "\n",
        "Now let's plot the histogram of **Number of parents and children of the passenger aboard(parch)**.\n"
      ],
      "metadata": {
        "id": "PPgReY8ZnLAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.histplot(full_data['Parch'],kde=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-4IKWcmLnOgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, most passengers don't have neither parents nor children aboard.\n",
        "<a id = \"kdeplot\"></a>\n",
        "### 2.2. kdeplot\n",
        "***Kernel Density Estimation (KDE)*** is a way to estimate the probability density function of a continuous random variable. It is used for ***non-parametric*** analysis. Setting the `hist` flag to False in `distplot` will yield the KDE plot. For bivariate distribution, we can plot a kde by using `jointplot()`. Pass value `‘kde’` to the parameter `kind` to plot kernel plot.\n",
        "\n",
        "**Note:** `distplot(data)` is used to visualize the ***parametric distribution*** of data. It plot both KDE and histogram on the same figure."
      ],
      "metadata": {
        "id": "UmQ-LwQJnSlE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(full_data['Age'], hist=False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q25UXkZVnUdK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see that most of the passenger has the age between 20 to 40"
      ],
      "metadata": {
        "id": "0KtQ-FYAnYsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "sns.distplot(full_data['Age'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D972WJBXnZh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Go back to the Table of Contents](#table_of_contents)\n",
        "** **\n",
        "<a id = \"Relational\"></a>\n",
        "## 3. Relational plots\n",
        "\n",
        "<a id = \"relplot\"></a>\n",
        "### 3.1. relplot\n",
        "Figure-level interface for drawing relational plots onto a FacetGrid.\n",
        "\n",
        "The function `relplot()` is named that way because it is designed to visualize many different statistical relationships. While scatter plots are a highly effective way of doing this, relationships where one variable represents a measure of time are better represented by a line. The `relplot()` function has a convenient `kind` parameter to let you easily switch to this alternate representation.\n"
      ],
      "metadata": {
        "id": "5-VIIn8Tndxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.relplot(x=\"Age\", y=\"Fare\", col=\"Pclass\", hue=\"Sex\", style=\"Sex\",kind=\"line\", data=full_data) # scatter can be used instead of \"line\" plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8GEqql2ZnhPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = \"scatterplot\"></a>\n",
        "### 3.2. scatterplot\n",
        "**Scatter plot** is the most convenient way to visualize the distribution where each observation is represented in two -dimensional plot via x and y axis."
      ],
      "metadata": {
        "id": "szBpjDN0nmaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "sns.scatterplot(x=\"Age\", y=\"Fare\", hue=\"Sex\", data=full_data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ThoOyZ4qn6pv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = \"lineplot\"></a>\n",
        "### 3.3. lineplot\n",
        "Draw a line plot with possibility of several semantic groupings.\n",
        "\n",
        "The relationship between `x` and `y` can be shown for different subsets of the data using the `hue, size`, and `style` parameters. These parameters control what visual semantics are used to identify the different subsets. It is possible to show up to three dimensions independently by using all three semantic types, but this style of plot can be hard to interpret and is often ineffective. Using redundant semantics (i.e. both **hue** and **style** for the same variable) can be helpful for making graphics more accessible.\n",
        "\n",
        "The default treatment of the hue (and to a lesser extent, size) semantic, if present, depends on whether the variable is inferred to represent **“numeric” or “categorical”** data. In particular, numeric variables are represented with a sequential colormap by default, and the legend entries show regular **“ticks”** with values that may or may not exist in the data. This behavior can be controlled through various parameters.\n",
        "\n",
        "By default, the plot aggregates over multiple `y` values at each value of `x` and shows an estimate of the central tendency and a confidence interval for that estimate.\n"
      ],
      "metadata": {
        "id": "j-u0xmodnr9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "sns.lineplot(x=\"Age\", y=\"Fare\", hue=\"Sex\", style=\"Sex\", data=full_data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pVz79eTIoA-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Go back to the Table of Contents](#table_of_contents)\n",
        "** **\n",
        "<a id = \"features\"></a>\n",
        "## 4. Categorical Plot\n",
        "When one or both the variables under study are categorical, we use plots like `striplot(), swarmplot(), etc,`. Seaborn provides interface to do so.\n",
        "<a id = \"barplot\"></a>\n",
        "### 4.1. barplot\n",
        "***The `barplot()` shows the relation between a categorical variable and a continuous variable.*** The data is represented in rectangular bars where the length the bar represents the proportion of the data in that category.\n",
        "**Bar plot** represents the estimate of ***central tendency.***\n",
        "\n",
        "**Note:** don't confuse **Bar plot** and **Histogram**. Please back to `2.1. distplot` section to see the difference.\n"
      ],
      "metadata": {
        "id": "xTYwS7FpoIRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "sns.barplot(x=\"Sex\", y=\"Survived\", hue=\"Pclass\", data=full_data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PBXXZJuLoJ5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**As we can see, More women survived than men.**\n",
        "<a id = \"stripplot\"></a>\n",
        "### 4.2. stripplot\n",
        "`stripplot()` is used when one of the variable under study is categorical. It represents the data in sorted order along any one of the axis."
      ],
      "metadata": {
        "id": "VPSIOByloQsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "sns.stripplot(x=\"Sex\", y=\"Age\",hue='Sex', data=full_data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q_PxVbUpoSnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To avoid the overlapping of the points, we can use the `jitter` to add some random noise to the data. This parameter will adjust the positions along the categorical axis. But Another option which can be used as an alternate to `‘Jitter’` is function `swarmplot()`.\n",
        "\n",
        "<a id = \"swarmplot\"></a>\n",
        "### 4.3. swarmplot\n",
        "This function positions each point of scatter plot on the categorical axis and thereby avoids overlapping points:"
      ],
      "metadata": {
        "id": "TH9K0uWvoVix"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "sns.swarmplot(x=\"Sex\", y=\"Age\",hue='Sex', data=full_data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OcAk_5-WoZ2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We can said that more passengers are approximally between 18 and 40 years old.**\n",
        "<a id = \"boxplot\"></a>\n",
        "### 4.4. boxplot\n",
        "**Boxplot** is a convenient way to visualize the distribution of data through their quartiles. Box plots usually have vertical lines extending from the boxes which are termed as **whiskers**. These whiskers indicate variability outside the upper and lower quartiles, hence Box Plots are also termed as **box-and-whisker plot** and **box-and-whisker diagram**. Any Outliers in the data are plotted as individual points.\n"
      ],
      "metadata": {
        "id": "qtpQJbfNodFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "sns.boxplot(x=\"Survived\", y=\"Age\", data=full_data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4qWevDX0ofs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We have some outliers for passengers survery through their age.**\n",
        "<a id = \"violinplot\"></a>\n",
        "### 4.5. violinplot\n",
        "**Violin Plots** are a combination of the **box plot** with the **kernel density estimates**. So, these plots are easier to analyze and understand the distribution of the data."
      ],
      "metadata": {
        "id": "ov7tWGmYoiYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.violinplot(x=\"Survived\", y=\"Age\", hue='Sex', data=full_data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ikW7DQPKojSP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The quartile and whisker values from the boxplot are shown inside the violin. As the violin plot uses KDE, the wider portion of violin indicates the higher density and narrow region represents relatively lower density. The Inter-Quartile range in boxplot and higher density portion in kde fall in the same region of each category of violin plot.\n",
        "\n",
        "<a id = \"countplot\"></a>\n",
        "### 4.6. countplot\n",
        "A special case in **barplot** is to show the no of observations in each category rather than computing a statistic for a second variable. For this, we use `countplot()`.\n"
      ],
      "metadata": {
        "id": "Bduc_3wDolNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.countplot(x=\"Survived\", data=full_data, palette=\"Blues\");\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ObZYDbslopJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = \"pointplot\"></a>\n",
        "### 4.7. pointplot\n",
        "**Point plots** serve same as **bar plots** but in a different style. Rather than the full bar, the value of the estimate is represented by the point at a certain height on the other axis."
      ],
      "metadata": {
        "id": "Hsbs6ZFVo3Tu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplots(figsize=(8, 8))\n",
        "sns.pointplot(x=\"Sex\", y=\"Survived\", hue=\"Pclass\", data=full_data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "l6P929QCo5_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We can see the average number of survivals of male and female in each class. From the plot we can understand that more number of females survived than males. In both males and females more number of survivals are from first\n",
        "class.**\n"
      ],
      "metadata": {
        "id": "jmBuEsk_o-AD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot says that, the number of passengers in the third class are higher than first and second class.**\n",
        "\n",
        "[Go back to the Table of Contents](#table_of_contents)\n",
        "** **\n",
        "<a id = \"Regression\"></a>\n",
        "## 5. Regression plots\n",
        "Most of the times, we use datasets that contain multiple quantitative variables, and the goal of an analysis is often to relate those variables to each other. This can be done through the ***regression lines***.\n",
        "\n",
        "While building the regression models, we often check for ***multicollinearity***, where we had to see the correlation between all the combinations of continuous variables and will take necessary action to remove multicollinearity if exists.\n",
        "\n",
        "There are two main functions in Seaborn to visualize a linear relationship determined through regression. These functions are `regplot()` and `lmplot()`.\n",
        "<a id = \"lmplot\"></a>\n",
        "### 5.1. lmplot\n",
        "**lmplot** has data as a required parameter and the x and y variables must be specified as strings. This data form at is called ***“long -form ”*** data"
      ],
      "metadata": {
        "id": "vLqfAYRoo-qF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.lmplot(x=\"Age\", y=\"Fare\", data=full_data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "g_u78gRgpBYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a id = \"regplot\"></a>\n",
        "### 5.2. regplot\n",
        "**regplot** accepts the x and y variables in a variety of formats including simple numpy arrays, pandas Series objects, or as references to variables in a pandas DataFrame."
      ],
      "metadata": {
        "id": "VCZWZ136pDcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplots(figsize=(10, 10))\n",
        "sns.regplot(x=\"Age\", y=\"Fare\", data=full_data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7Ogxkf-npGal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplots(figsize=(10, 10))\n",
        "sns.regplot(x=\"Fare\", y=\"Fare\", data=full_data)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9MReLRj8piOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Go back to the Table of Contents](#table_of_contents)\n",
        "** **\n",
        "<a id = \"Matrix\"></a>\n",
        "## 6. Matrix plots\n",
        "\n",
        "<a id = \"heatmap\"></a>\n",
        "### 6.1. heatmap\n",
        "\n",
        "Visualizing data with **heatmaps** is a great way to do exploratory data analysis, when you have a data set with multiple variables. Heatmaps can reveal general pattern in the dataset, instantly. And it is very easy to make beautiful heatmaps with Seaborn library in Python.\n",
        "\n",
        "Now let's plot the correlation matrix of our data with a heatmap."
      ],
      "metadata": {
        "id": "Bo3-FGYiplK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplots(figsize=(10, 10))\n",
        "sns.heatmap(full_data.corr(), cmap = \"YlGnBu\", annot=True, fmt=\".2f\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GGR9a4MNpoL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**We note that correlations beteewn variables are weak.**\n"
      ],
      "metadata": {
        "id": "XByQLLGnprt_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Go back to the Table of Contents](#table_of_contents)\n",
        "** **\n",
        "<a id = \"features\"></a>\n",
        "## 7. Multi-plot grids\n",
        "\n",
        "<a id = \"Facet\"></a>\n",
        "### 7.1. Facet grids\n",
        "A useful approach to explore medium-dimensional data, is by drawing multiple instances of the same plot on different subsets of your dataset. This technique is commonly called as ***“lattice”***, or ***“trellis”*** plotting, and it is related to the idea of ***“small multiples”***. To use these features, your data has to be in a Pandas DataFrame.\n",
        "\n",
        "**Facet grid** forms a matrix of panels defined by row and column by dividing the variables. Due of panels, a single plot looks like multiple plots. It is very helpful to analyze all combinations in two discrete variables.\n",
        "\n",
        "**FacetGrid** object takes a dataframe as input and the names of the variables that will form the row, column, or hue dimensions of the grid. The variables should be categorical and the data at each level of the variable will be used for a facet along that axis.\n",
        "\n",
        "The advantage of using Facet is, we can input another variable into the plot. We can make many column facets and align them with the rows of the grid:\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D_kj3ud4ptZu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### FacetGrid.map\n",
        "The main approach for visualizing data on this grid is with the `FacetGrid.map()` method."
      ],
      "metadata": {
        "id": "OLGYjBbpp2W3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the FacetGrid object\n",
        "g = sns.FacetGrid(full_data, col='Survived', row='Pclass')\n",
        "\n",
        "g.map(plt.hist, 'Age')\n",
        "g.add_legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dy7aY2Cjp4YK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Go back to the Table of Contents](#table_of_contents)\n",
        "** **\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "This tutorial took you through the basics and various functions of Seaborn. It is specifically useful for people working on data analysis. After completing this tutorial, you are now at a moderate level of expertise from where you can take yourself to higher levels of expertise.\n",
        "\n",
        "Stay update, practice, practice and practice to developpe data visualization skill.\n",
        "\n",
        "**Thanks and Good luck.**"
      ],
      "metadata": {
        "id": "0cUEOVJ6p_TS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References:\n",
        "* https://cmdlinetips.com/2020/01/ especially for heatmap and clustermap.\n",
        "* https://seaborn.pydata.org/\n",
        "* https://seaborn.pydata.org/api.html#api-ref"
      ],
      "metadata": {
        "id": "xIOQ7drbqGIz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TRAINING DATA PRE-PROCESSING**\n",
        "The first step in the machine learning pipeline is to clean and transform the training data into a useable format for analysis and modeling.   \n",
        "\n",
        "As such, data pre-processing addresses:\n",
        "- Assumptions about data shape\n",
        "- Incorrect data types\n",
        "- Outliers or errors\n",
        "- Missing values\n",
        "- Categorical variables"
      ],
      "metadata": {
        "id": "cF5qnC2_qIKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "full_data = pd.read_csv('/content/titanic_dataset.csv')"
      ],
      "metadata": {
        "id": "hYBVoVbrqMId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Shape**  \n",
        "After loading the dataset, I examine its shape to get a better sense of the data and the information it contains.  "
      ],
      "metadata": {
        "id": "Eg2Qa6y4qOp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data shape\n",
        "print('train data:',full_data.shape)"
      ],
      "metadata": {
        "id": "Uh2tgxUYqQyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View first few rows\n",
        "full_data.head(5)"
      ],
      "metadata": {
        "id": "LRLI8gSXqTPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Missing Data**  \n",
        "From the entry totals above, there appears to be missing data.  A heatmap will help better visualize what features as missing the most information."
      ],
      "metadata": {
        "id": "va6nO546qW7u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Heatmap\n",
        "sns.heatmap(full_data.isnull(),yticklabels = False, cbar = False,cmap = 'tab20c_r')\n",
        "plt.title('Missing Data: Training Set')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qPv2DpkJqY_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 'Age' variable is missing roughly 20% of its data. This proportion is likely small enough for reasonable replacements using some form of imputation as well (using the knowledge of the other columns to fill in reasonable values).\n",
        "However, too much data from the 'Cabin' column is missing to do anything useful with it at a basic level. This column may need to be dropped from the data set altogether or change to another feature such as 'Cabin Known: 1 or 0'.  \n",
        "\n",
        "We want to fill in missing age data instead of just dropping the missing age data rows. One way to do this is by filling in the mean age of all the passengers (imputation).\n",
        "However, we can be smarter about this and check the average age by passenger class.\n"
      ],
      "metadata": {
        "id": "RJr_I6krqcsb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize = (10,7))\n",
        "sns.boxplot(x = 'Pclass', y = 'Age', data = full_data, palette= 'GnBu_d').set_title('Age by Passenger Class')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rlCp8N_-qfPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naturally, the wealthier passengers in the higher classes tend to be older . We'll use these average age values to impute based on Pclass for Age.\n"
      ],
      "metadata": {
        "id": "duzeGhTqqj9Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imputation function\n",
        "def impute_age(cols):\n",
        "    Age = cols[0]\n",
        "    Pclass = cols[1]\n",
        "\n",
        "    if pd.isnull(Age):\n",
        "\n",
        "        if Pclass == 1:\n",
        "            return 37\n",
        "\n",
        "        elif Pclass == 2:\n",
        "\n",
        "            return 29\n",
        "\n",
        "        else:\n",
        "            return 24\n",
        "\n",
        "    else:\n",
        "        return Age\n",
        "\n",
        "# Apply the function to the Age column\n",
        "full_data['Age']=full_data[['Age','Pclass']].apply(impute_age, axis =1 )"
      ],
      "metadata": {
        "id": "JrWPsl0uqpAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The Cabin column has too many missing values to do anything useful with, so it would be best to remove it from the data frame altogether."
      ],
      "metadata": {
        "id": "lCqq0PjkqsSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Cabin feature\n",
        "full_data.drop('Cabin', axis = 1, inplace = True)"
      ],
      "metadata": {
        "id": "zJ_wSmbdquO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there is only one missing value in Embarked, that observation can just be removed."
      ],
      "metadata": {
        "id": "e1OzesCTqwjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove rows with missing data\n",
        "full_data.dropna(inplace = True)"
      ],
      "metadata": {
        "id": "g0VqbGApqzh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Name and Ticket can be removed from the dataset as these features do not provide additional information about a passenger's liklihood of survival.    \n",
        "\n",
        "The remaining non-null objects, Sex and Embarked, will need to be specified as categories for better analysis results downstream.  "
      ],
      "metadata": {
        "id": "Cat_nzpMq2ht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove unnecessary columns\n",
        "full_data.drop(['Name','Ticket'], axis = 1, inplace = True)\n",
        "\n",
        "# Convert objects to category data type\n",
        "objcat = ['Sex','Embarked']\n",
        "\n",
        "for colname in objcat:\n",
        "    full_data[colname] = full_data[colname].astype('category')"
      ],
      "metadata": {
        "id": "u9e6_Ps-q5IH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Numeric Features**"
      ],
      "metadata": {
        "id": "7g9lGuVAq78M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numeric summary\n",
        "full_data.describe()"
      ],
      "metadata": {
        "id": "kvpbycNgq9V0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PassengerId can be removed from the dataset because it does not add any useful information in predicting a passenger's survival.  The remaining variables are the correct data type."
      ],
      "metadata": {
        "id": "6_qSd3HgrBHl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove PassengerId\n",
        "full_data.drop('PassengerId', inplace = True, axis = 1)"
      ],
      "metadata": {
        "id": "ngAiNsaqrC1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GETTING MODEL READY**\n",
        "\n",
        "Now that we've explored the data, it is time to get these features 'model ready'. Categorial features will need to be converted into 'dummy variables', otherwise a machine learning algorithm will not be able to take in those features as inputs."
      ],
      "metadata": {
        "id": "PrLOzwI4rFqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of train data\n",
        "full_data.shape"
      ],
      "metadata": {
        "id": "VQ3KfJ7prIiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify categorical features\n",
        "full_data.select_dtypes(['category']).columns"
      ],
      "metadata": {
        "id": "euU8uvWZrK_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical variables into 'dummy' or indicator variables\n",
        "sex = pd.get_dummies(full_data['Sex'], drop_first = True) # drop_first prevents multi-collinearity\n",
        "embarked = pd.get_dummies(full_data['Embarked'], drop_first = True)"
      ],
      "metadata": {
        "id": "FTr73A8ZrM-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_data.head()"
      ],
      "metadata": {
        "id": "LGJQQ5dZrPlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add new dummy columns to data frame\n",
        "full_data = pd.concat([full_data, sex, embarked], axis = 1)\n",
        "full_data.head(5)"
      ],
      "metadata": {
        "id": "SP6MA-CPrSP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop unecessary columns\n",
        "full_data.drop(['Sex', 'Embarked'], axis = 1, inplace = True)\n",
        "\n",
        "# Shape of train data\n",
        "print('train_data shape',full_data.shape)\n",
        "\n",
        "# Confirm changes\n",
        "full_data.head()"
      ],
      "metadata": {
        "id": "1DuqLMNxrV3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        ">Now the train data is perfect for a machine learning algorithm:  \n",
        "- all the data is numeric\n",
        "- everything is concatenated together"
      ],
      "metadata": {
        "id": "us-5Iooyrcyg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **OBJECTIVE 2: MACHINE LEARNING**\n",
        "Next, I will feed these features into various classification algorithms to determine the best performance using a simple framework: **Split, Fit, Predict, Score It.**"
      ],
      "metadata": {
        "id": "cIr7jQr6rgWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data to be used in the models\n",
        "# Create matrix of features\n",
        "x = full_data.drop('Survived', axis = 1) # grabs everything else but 'Survived'\n",
        "\n",
        "# Create target variable\n",
        "y = full_data['Survived'] # y is the column we're trying to predict\n",
        "\n",
        "# Use x and y variables to split the training data into train and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = .20, random_state = 101)"
      ],
      "metadata": {
        "id": "i6X-2rBorf9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit\n",
        "# Import model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create instance of model\n",
        "lreg = LogisticRegression()\n",
        "\n",
        "# Pass training data into model\n",
        "lreg.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "jq5gHKs1rdc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict\n",
        "y_pred_lreg = lreg.predict(x_test)\n",
        "print(y_pred_lreg)"
      ],
      "metadata": {
        "id": "WgvwHFIlruqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Score It\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "print('Classification Model')\n",
        "# Accuracy\n",
        "print('--'*40)\n",
        "logreg_accuracy = round(accuracy_score(y_test, y_pred_lreg) * 100,2)\n",
        "print('Accuracy', logreg_accuracy,'%')"
      ],
      "metadata": {
        "id": "iM70g0shrzBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Interpretation**  \n",
        "**Accuracy**  \n",
        "82% of the model's predictions are correct."
      ],
      "metadata": {
        "id": "Irq_E_jHr2UT"
      }
    }
  ]
}